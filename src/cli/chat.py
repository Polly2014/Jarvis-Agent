"""
Jarvis CLI â€” èŠå¤©å¾ªç¯ä¸è¡¥å…¨å™¨
"""
import json
from typing import Optional

from prompt_toolkit import PromptSession
from prompt_toolkit.completion import Completer, Completion
from prompt_toolkit.history import FileHistory
from prompt_toolkit.styles import Style

from .common import (
    console, JARVIS_HOME, VERSION,
    get_status_summary, get_unread_discoveries, format_discovery_time,
    is_first_run, detect_natural_intent, load_llm_config,
    ensure_jarvis_home,
)
from .daemon_cmds import _do_start_daemon, _do_rest, _do_status
from .memory_cmds import _do_recall, _do_think, _do_insights
from .explore_cmds import _do_discoveries, _do_explore, _do_projects, _do_skills, _do_init

from rich.panel import Panel


# â”€â”€ æ–œæ å‘½ä»¤è¡¥å…¨å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class JarvisCompleter(Completer):
    """Jarvis æ–œæ å‘½ä»¤è¡¥å…¨å™¨"""

    SLASH_COMMANDS = {
        "/start": "å¯åŠ¨ daemon åå°ç›‘æ§",
        "/rest": "åœæ­¢ daemon",
        "/status": "æŸ¥çœ‹çŠ¶æ€",
        "/discoveries": "æŸ¥çœ‹å‘ç°è®°å½•",
        "/recall": "æœç´¢è®°å¿† (ç”¨æ³•: /recall å…³é”®è¯)",
        "/think": "è§¦å‘ä¸€æ¬¡æ€è€ƒ",
        "/insights": "æŸ¥çœ‹æœ€è¿‘æ´å¯Ÿ",
        "/explore": "æ¢ç´¢ç›®å½•",
        "/projects": "åˆ—å‡ºå·²å‘ç°é¡¹ç›®",
        "/skills": "åˆ—å‡º skills",
        "/init": "åˆå§‹åŒ–é…ç½®",
        "/help": "æ˜¾ç¤ºå¸®åŠ©",
        "/exit": "é€€å‡ºèŠå¤©",
        "/quit": "é€€å‡ºèŠå¤©",
    }

    def get_completions(self, document, complete_event):
        text = document.text_before_cursor

        if text.startswith("/"):
            word = text.lower()
            for cmd, desc in self.SLASH_COMMANDS.items():
                if cmd.startswith(word):
                    yield Completion(
                        cmd,
                        start_position=-len(word),
                        display=f"{cmd}",
                        display_meta=desc,
                    )


# â”€â”€ è¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def show_welcome_banner():
    """æ˜¾ç¤ºæ¬¢è¿æ¨ªå¹…å’ŒçŠ¶æ€"""
    status_emoji, status_text, unread = get_status_summary()

    header = f"[bold cyan]ğŸ¥š Jarvis[/bold cyan] v{VERSION}  {status_emoji} {status_text}"
    console.print(Panel(header, border_style="cyan", padding=(0, 1)))

    if unread > 0:
        discoveries = get_unread_discoveries(limit=3)
        if discoveries:
            console.print()
            console.print(f"[bold yellow]ğŸ“‹ æœ€è¿‘å‘ç°[/bold yellow] [dim]({unread}æ¡æœªè¯»)[/dim]")

            for d in discoveries:
                importance = d.get("importance", 3)
                stars = "â­" * min(importance, 5)
                time_str = format_discovery_time(d.get("timestamp", ""))
                title = d.get("title", "æœªçŸ¥å‘ç°")
                if len(title) > 40:
                    title = title[:37] + "..."
                console.print(f"  {stars} [dim][{time_str}][/dim] {title}")

            console.print(f"  [dim]â””â”€ /discoveries æŸ¥çœ‹å…¨éƒ¨ Â· /discoveries --ack æ ‡è®°å·²è¯»[/dim]")
            console.print()


def show_slash_help():
    """æ˜¾ç¤ºæ–œæ å‘½ä»¤å¸®åŠ©"""
    help_text = """
[bold]æ–œæ å‘½ä»¤:[/bold]
  /start       å¯åŠ¨ daemon åå°ç›‘æ§
  /rest        åœæ­¢ daemon
  /status      æŸ¥çœ‹çŠ¶æ€
  /discoveries æŸ¥çœ‹å‘ç°è®°å½•
  /recall      æœç´¢è®°å¿† (ç”¨æ³•: /recall å…³é”®è¯)
  /think       è§¦å‘ä¸€æ¬¡æ€è€ƒ
  /insights    æŸ¥çœ‹æœ€è¿‘æ´å¯Ÿ
  /explore     æ¢ç´¢ç›®å½•
  /projects    åˆ—å‡ºå·²å‘ç°é¡¹ç›®
  /skills      åˆ—å‡º skills
  /init        åˆå§‹åŒ–é…ç½®
  /help        æ˜¾ç¤ºæœ¬å¸®åŠ©
  /exit /quit  é€€å‡ºèŠå¤©

[dim]ä¹Ÿå¯ä»¥ç›´æ¥ç”¨è‡ªç„¶è¯­è¨€ï¼š"å¸®æˆ‘æŒ‚æœº"ã€"ä¼‘æ¯"ã€"ä½ åœ¨å¹²å˜›"[/dim]
"""
    console.print(help_text)


def handle_slash_command(cmd: str) -> bool:
    """
    å¤„ç†æ–œæ å‘½ä»¤
    Returns: True è¡¨ç¤ºå·²å¤„ç†ï¼ŒFalse è¡¨ç¤ºéœ€è¦é€€å‡º
    """
    cmd = cmd.strip().lower()
    parts = cmd.split(maxsplit=1)
    command = parts[0]
    args = parts[1] if len(parts) > 1 else None

    if command in ("/exit", "/quit", "/q"):
        console.print("\n[dim]å†è§ï¼éšæ—¶å‘¼å”¤æˆ‘ã€‚[/dim] ğŸ‘‹")
        return False

    elif command == "/help":
        show_slash_help()
    elif command == "/status":
        _do_status()
    elif command == "/start":
        _do_start_daemon()
    elif command == "/rest":
        _do_rest()
    elif command == "/discoveries":
        _do_discoveries()
    elif command == "/recall":
        _do_recall(args)
    elif command == "/think":
        _do_think()
    elif command == "/insights":
        _do_insights()
    elif command == "/explore":
        _do_explore(args)
    elif command == "/projects":
        _do_projects()
    elif command == "/skills":
        _do_skills()
    elif command == "/init":
        _do_init()
    else:
        console.print(f"[red]æœªçŸ¥å‘½ä»¤: {command}[/red]")
        console.print("[dim]è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤[/dim]")

    return True


# â”€â”€ èŠå¤©å¾ªç¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_prompt_session() -> PromptSession:
    """åˆ›å»ºå¸¦è¡¥å…¨çš„ PromptSession"""
    style = Style.from_dict({
        'prompt': 'bold #00ff00',
        'completion-menu.completion': 'bg:#333333 #ffffff',
        'completion-menu.completion.current': 'bg:#00aa00 #ffffff',
        'completion-menu.meta.completion': 'bg:#333333 #888888',
        'completion-menu.meta.completion.current': 'bg:#00aa00 #ffffff',
    })

    history_path = JARVIS_HOME / "chat_history"

    return PromptSession(
        completer=JarvisCompleter(),
        style=style,
        history=FileHistory(str(history_path)),
        complete_while_typing=False,
    )


def _do_ask(question: str):
    """å•æ¬¡æé—®ï¼ˆstreamingï¼‰"""
    import httpx

    llm = load_llm_config()
    base_url = llm.get("base_url", "http://localhost:23335/api/openai")
    model = llm.get("model", "claude-sonnet-4")
    auth_token = llm.get("auth_token", "")

    console.print(f"\n[bold green]ä½ [/bold green]: {question}")
    console.print("\n[bold cyan]Jarvis[/bold cyan]: ", end="")

    try:
        with httpx.Client(timeout=120.0, trust_env=False) as client:
            with client.stream(
                "POST",
                f"{base_url}/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {auth_token}",
                    "Content-Type": "application/json",
                },
                json={
                    "model": model,
                    "max_tokens": 2000,
                    "stream": True,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ Jarvisï¼ŒPolly çš„ç§äºº AI åŠ©æ‰‹ã€‚ç®€æ´ã€æœ‰å¸®åŠ©ã€å¯ä»¥ç”¨ emojiã€‚"},
                        {"role": "user", "content": question},
                    ],
                },
            ) as response:
                if response.status_code != 200:
                    console.print(f"[red]API é”™è¯¯: {response.status_code}[/red]")
                    return

                for line in response.iter_lines():
                    if not line or not line.startswith("data: "):
                        continue
                    data_str = line[6:]
                    if data_str == "[DONE]":
                        break
                    try:
                        chunk = json.loads(data_str)
                        content = chunk.get("choices", [{}])[0].get("delta", {}).get("content", "")
                        if content:
                            print(content, end="", flush=True)
                    except json.JSONDecodeError:
                        continue

        print("\n")

    except Exception as e:
        console.print(f"\n[red]è¿æ¥é”™è¯¯: {e}[/red]")


def run_chat_loop():
    """ç»Ÿä¸€çš„èŠå¤©å¾ªç¯ï¼šæ–œæ å‘½ä»¤è¡¥å…¨ + è‡ªç„¶è¯­è¨€æ§åˆ¶ + LLM å¯¹è¯"""
    import httpx

    if is_first_run():
        console.print("\n[yellow]ğŸ¥š é¦–æ¬¡è¿è¡Œï¼è®©æˆ‘ä»¬å…ˆåˆå§‹åŒ–é…ç½®ã€‚[/yellow]")
        console.print("[dim]è¾“å…¥ /init å¼€å§‹åˆå§‹åŒ–ï¼Œæˆ–ç›´æ¥å¼€å§‹èŠå¤©[/dim]\n")

    llm = load_llm_config()
    base_url = llm.get("base_url", "http://localhost:23335/api/openai")
    model = llm.get("model", "claude-sonnet-4")
    auth_token = llm.get("auth_token", "")

    messages: list[dict] = []
    session = create_prompt_session()

    console.print("[dim]è¾“å…¥ / åæŒ‰ Tab è¡¥å…¨å‘½ä»¤ï¼Œâ†‘â†“ æŸ¥çœ‹å†å²[/dim]\n")

    while True:
        try:
            user_input = session.prompt("ä½ > ").strip()

            if not user_input:
                continue

            # æ–œæ å‘½ä»¤
            if user_input.startswith("/"):
                if not handle_slash_command(user_input):
                    break
                continue

            # é€€å‡ºå…¼å®¹
            if user_input.lower() in ("exit", "quit", "q"):
                console.print("\n[dim]å†è§ï¼éšæ—¶å‘¼å”¤æˆ‘ã€‚[/dim] ğŸ‘‹")
                break

            # è‡ªç„¶è¯­è¨€æ„å›¾
            intent = detect_natural_intent(user_input)
            if intent == "start":
                _do_start_daemon()
                continue
            elif intent == "rest":
                _do_rest()
                continue
            elif intent == "status":
                _do_status()
                continue

            # LLM å¯¹è¯ (streaming)
            messages.append({"role": "user", "content": user_input})

            console.print("\n[bold cyan]Jarvis[/bold cyan]: ", end="")
            full_reply = ""

            try:
                with httpx.Client(timeout=120.0, trust_env=False) as client:
                    with client.stream(
                        "POST",
                        f"{base_url}/v1/chat/completions",
                        headers={
                            "Authorization": f"Bearer {auth_token}",
                            "Content-Type": "application/json",
                        },
                        json={
                            "model": model,
                            "max_tokens": 2000,
                            "stream": True,
                            "messages": [
                                {"role": "system", "content": "ä½ æ˜¯ Jarvisï¼ŒPolly çš„ç§äºº AI åŠ©æ‰‹ã€‚ç®€æ´ã€æœ‰å¸®åŠ©ã€å¯ä»¥ç”¨ emojiã€‚"},
                                *messages[-10:],
                            ],
                        },
                    ) as response:
                        if response.status_code != 200:
                            console.print(f"[red]API é”™è¯¯: {response.status_code}[/red]\n")
                            continue

                        for line in response.iter_lines():
                            if not line or not line.startswith("data: "):
                                continue
                            data_str = line[6:]
                            if data_str == "[DONE]":
                                break
                            try:
                                chunk = json.loads(data_str)
                                content = chunk.get("choices", [{}])[0].get("delta", {}).get("content", "")
                                if content:
                                    print(content, end="", flush=True)
                                    full_reply += content
                            except json.JSONDecodeError:
                                continue

                print("\n")
                messages.append({"role": "assistant", "content": full_reply})

            except Exception as e:
                console.print(f"\n[red]è¿æ¥é”™è¯¯: {e}[/red]\n")

        except KeyboardInterrupt:
            console.print("\n[dim]å†è§ï¼(daemon ä»åœ¨åå°è¿è¡Œ)[/dim] ğŸ‘‹")
            break
